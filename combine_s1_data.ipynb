{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#s1_old = pd.read_csv('input_data/s1_data.csv', index_col=[0,1])\n",
    "s1_zonal_0218 = pd.read_csv('input_data/S1_0218_zonal.csv')\n",
    "s1_zonal_0218.drop(columns='OID_', inplace=True)\n",
    "s1_zonal_0218['date'] = '0218'\n",
    "s1_zonal_0218.index = pd.MultiIndex.from_arrays([s1_zonal_0218['date'], s1_zonal_0218['S1_pixel_ID']])\n",
    "s1_zonal_0218.drop(columns=['date','S1_pixel_ID'], inplace=True)\n",
    "s1_zonal_0218.sort_index(inplace=True)\n",
    "\n",
    "s1_zonal_0302 = pd.read_csv('input_data/S1_0302_zonal.csv')\n",
    "s1_zonal_0302.drop(columns='OID_', inplace=True)\n",
    "s1_zonal_0302['date'] = '0302'\n",
    "s1_zonal_0302.index = pd.MultiIndex.from_arrays([s1_zonal_0302['date'], s1_zonal_0302['S1_pixel_ID']])\n",
    "s1_zonal_0302.drop(columns=['date','S1_pixel_ID'], inplace=True)\n",
    "s1_zonal_0302.sort_index(inplace=True)\n",
    "\n",
    "s1_data = pd.concat([s1_zonal_0218, s1_zonal_0302])\n",
    "# s1_data.to_csv('input_data/s1_zonal_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Original manuscript submission\n",
    "# s1_class_0218 = pd.read_csv('input_data/classification_data_0218.csv')\n",
    "# s1_class_0218.drop(columns='OID_', inplace=True)\n",
    "# s1_class_0218['date'] = '0218'\n",
    "# s1_class_0218.index = pd.MultiIndex.from_arrays([s1_class_0218['date'], s1_class_0218['S1_pixel_ID']])\n",
    "# s1_class_0218.drop(columns=['date','S1_pixel_ID'], inplace=True)\n",
    "# s1_class_0218.sort_index(inplace=True)\n",
    "\n",
    "# s1_class_0302 = pd.read_csv('input_data/classification_data_0302.csv')\n",
    "# s1_class_0302.drop(columns='OID_', inplace=True)\n",
    "# s1_class_0302['date'] = '0302'\n",
    "# s1_class_0302.index = pd.MultiIndex.from_arrays([s1_class_0302['date'], s1_class_0302['S1_pixel_ID']])\n",
    "# s1_class_0302.drop(columns=['date','S1_pixel_ID'], inplace=True)\n",
    "# s1_class_0302.sort_index(inplace=True)\n",
    "\n",
    "# s1_data = pd.concat([s1_class_0218, s1_class_0302]).dropna()\n",
    "# s1_data.to_csv('input_data/s1_classification_data.csv')\n",
    "\n",
    "# Revisions #1 for paper\n",
    "s1_class_0218 = pd.read_csv('input_data/classification_data_0218_rev1.csv')\n",
    "s1_class_0218.drop(columns='OID_', inplace=True)\n",
    "s1_class_0218['date'] = '0218'\n",
    "# Drop duplicate S1 pixels, keeping the entry with the highest area\n",
    "area_maxes_0218 = s1_class_0218.groupby(['date', 'S1_pixel_ID']).AREA.transform(max)\n",
    "s1_class_0218 = s1_class_0218.loc[s1_class_0218['AREA'] == area_maxes_0218]\n",
    "s1_class_0218.index = pd.MultiIndex.from_arrays([s1_class_0218['date'], s1_class_0218['S1_pixel_ID']])\n",
    "s1_class_0218.drop(columns=['date','S1_pixel_ID'], inplace=True)\n",
    "s1_class_0218.sort_index(inplace=True)\n",
    "\n",
    "s1_class_0302 = pd.read_csv('input_data/classification_data_0302_rev1.csv')\n",
    "s1_class_0302.drop(columns='OID_', inplace=True)\n",
    "s1_class_0302['date'] = '0302'\n",
    "# Drop duplicate S1 pixels, keeping the entry with the highest area\n",
    "area_maxes_0302 = s1_class_0302.groupby(['date', 'S1_pixel_ID']).AREA.transform(max)\n",
    "s1_class_0302 = s1_class_0302.loc[s1_class_0302['AREA'] == area_maxes_0302]\n",
    "s1_class_0302.index = pd.MultiIndex.from_arrays([s1_class_0302['date'], s1_class_0302['S1_pixel_ID']])\n",
    "s1_class_0302.drop(columns=['date','S1_pixel_ID'], inplace=True)\n",
    "s1_class_0302.sort_index(inplace=True)\n",
    "\n",
    "s1_data = pd.concat([s1_class_0218, s1_class_0302]).dropna()\n",
    "s1_data.to_csv('input_data/s1_classification_data_rev1.csv')\n",
    "\n",
    "# Calculate class_assignment category based on a range of threshold values\n",
    "for thresh in [60, 70, 80, 90, 100]:\n",
    "    s1_data['class_assignment'] = [s1_data.loc[i,'class'] if s1_data.loc[i,'AREA'] >= thresh else 'NC' for i in s1_data.index]\n",
    "    s1_data.to_csv(f'input_data/s1_classification_data_rev1_t{thresh}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('uavsar_pytools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0b33513e00be7b6ac56cc8d14ba4cba103a38f94a885c5a83e4ca1942b728d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
