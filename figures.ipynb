{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import re\n",
    "from scipy.integrate import cumulative_trapezoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1x3 scatter plots of RF regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_unit = 'dB'\n",
    "second_stat = 'max'\n",
    "\n",
    "metrics_dir = 'output/rf_metrics/single_date'\n",
    "predict_dir = 'output/rf_predictions/single_date'\n",
    "metrics_multi_dir = 'output/rf_metrics/multi_date'\n",
    "predict_multi_dir = 'output/rf_predictions/multi_date'\n",
    "\n",
    "metrics_0219 = sorted(glob(f'{metrics_dir}/0219/*{s1_unit}*_10m_*.csv'))\n",
    "predict_0219 = sorted(glob(f'{predict_dir}/0219/*{s1_unit}*_10m_*.csv'))\n",
    "metrics_0302 = sorted(glob(f'{metrics_dir}/0302/*{s1_unit}*_10m_*csv'))\n",
    "predict_0302 = sorted(glob(f'{predict_dir}/0302/*{s1_unit}*_10m_*.csv'))\n",
    "metrics_multi = sorted(glob(f'{metrics_multi_dir}/*{s1_unit}*_10m_*.csv'))\n",
    "predict_multi = sorted(glob(f'{predict_multi_dir}/*{s1_unit}*_10m_*.csv'))\n",
    "\n",
    "#fig, ax = plt.subplots(1, 3, figsize=(18,6))\n",
    "\n",
    "for i in range(len(metrics_0219)):#[26:28]:\n",
    "    if '_10m_' not in metrics_0219[i]:\n",
    "        continue\n",
    "    files_0219 = (metrics_0219[i], predict_0219[i])\n",
    "    files_0302 = (metrics_0302[i], predict_0302[i])\n",
    "    files_multi = (metrics_multi[i], predict_multi[i])\n",
    "    title_prefix = ['Feb 18: ', 'Mar 2: ', 'Both dates: ']\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18,6))\n",
    "    j = 0\n",
    "    for date in [files_0219, files_0302, files_multi]:\n",
    "        mf = date[0]\n",
    "        pf = date[1]\n",
    "        # Set up dataframes\n",
    "        metrics_df = pd.read_csv(mf, index_col=0)\n",
    "        metrics_df.index.name = 'run_no'\n",
    "        predict_df = pd.read_csv(pf, index_col=0)\n",
    "        predict_df['run_no'] = predict_df['run_no'].astype(int)\n",
    "        predict_df.index.name = 'sample'\n",
    "        predict_df.index = predict_df.index % len(predict_df)//100 # reset sample count for each run\n",
    "        predict_df.index = pd.MultiIndex.from_arrays([predict_df['run_no'], predict_df.index])\n",
    "        predict_df.drop(columns='run_no', inplace=True)\n",
    "\n",
    "        # Loop through runs for scatter plot\n",
    "        \n",
    "        ax[j].scatter(predict_df['predict'], predict_df['valid'], s=2, marker='.', color='k')\n",
    "        ax[j].set_xlim(ax[j].get_ylim())\n",
    "        # ax[j].set_xticks(ax[j].get_yticks())\n",
    "        ax[j].tick_params(axis='x', labelrotation=90)\n",
    "        # ax[j].set_xlim(ax[j].get_ylim())\n",
    "        ax[j].set_xlabel('Measured', fontsize=18, labelpad=12)\n",
    "        \n",
    "        ax[j].set_title(f'{title_prefix[j]}Avg R$^2$ = {str(round(metrics_df[\"r2\"].mean(), 2))}', fontsize=20)\n",
    "\n",
    "        j += 1\n",
    "\n",
    "        # hbin = ax[1].hexbin(predict_df['predict'], predict_df['valid'], cmap='viridis',\n",
    "        #                     gridsize=50,\n",
    "        #                     extent=(ax[0].get_xlim()[0], ax[0].get_xlim()[1], ax[0].get_ylim()[0], ax[0].get_ylim()[1]))\n",
    "        # cbar = plt.colorbar(hbin, ax=ax[1])\n",
    "        # ax[1].set_xlim(ax[0].get_xlim())\n",
    "        # ax[1].set_ylim(ax[0].get_ylim())\n",
    "\n",
    "    xmin, xmax = ax[0].get_xlim()\n",
    "    ymin, ymax = ax[0].get_ylim()\n",
    "    for axx in (ax[1], ax[2]):\n",
    "        x0, x1 = axx.get_xlim()\n",
    "        if x0 < xmin:\n",
    "            xmin = x0\n",
    "        if x1 > xmax:\n",
    "            xmax = x1\n",
    "        y0, y1 = axx.get_ylim()\n",
    "        if y0 < ymin:\n",
    "            ymin = y0\n",
    "        if y1 > ymax:\n",
    "            ymax = y1\n",
    "    for axx in ax.flatten():\n",
    "        axx.set_xlim(xmin, xmax)\n",
    "        axx.set_ylim(ymin, ymax)\n",
    "        axx.plot((axx.get_xlim()), (axx.get_ylim()), 'r--')\n",
    "    \n",
    "    ax[0].set_ylabel('Predicted', fontsize=18, labelpad=12)\n",
    "    # check for specified scale in filename\n",
    "    if not re.findall(r'_\\d{1,2}[a-z]{1,2}_', mf):\n",
    "        # Scale not specified (10m pixels)\n",
    "        fig.suptitle('RF target: 10 m ' + mf.split('_dB_')[-1][:-4], fontsize=22)\n",
    "    else:\n",
    "        fig.suptitle('RF target: ' + mf.split('_dB_')[-1][:-4], fontsize=22)\n",
    "    \n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig_fname = f\"output/figures/scatter/{mf.split('/')[-1].split('.')[0]}.png\"\n",
    "    fig.savefig(fig_fname, dpi=300, facecolor='white')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps of r^2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_unit = 'dB'\n",
    "second_stat = 'mean'\n",
    "\n",
    "metrics_dir = 'output/rf_metrics/single_date'\n",
    "predict_dir = 'output/rf_predictions/single_date'\n",
    "metrics_multi_dir = 'output/rf_metrics/multi_date'\n",
    "predict_multi_dir = 'output/rf_predictions/multi_date'\n",
    "\n",
    "metrics_0219 = sorted(glob(f'{metrics_dir}/0219/*{s1_unit}*.csv'))\n",
    "predict_0219 = sorted(glob(f'{predict_dir}/0219/*{s1_unit}*.csv'))\n",
    "metrics_0302 = sorted(glob(f'{metrics_dir}/0302/*{s1_unit}*.csv'))\n",
    "predict_0302 = sorted(glob(f'{predict_dir}/0302/*{s1_unit}*.csv'))\n",
    "metrics_multi = sorted(glob(f'{metrics_multi_dir}/*{s1_unit}*.csv'))\n",
    "predict_multi = sorted(glob(f'{predict_multi_dir}/*{s1_unit}*.csv'))\n",
    "\n",
    "zonal_0219 = [f for f in metrics_0219 if 'zonal' in f]\n",
    "zonal_0302 = [f for f in metrics_0302 if 'zonal' in f]\n",
    "subset_0219 = [f for f in zonal_0219 if second_stat in f.split('.')[0].split('_')[-1]]\n",
    "subset_0302 = [f for f in zonal_0302 if second_stat in f.split('.')[0].split('_')[-1]]\n",
    "\n",
    "ind = ['10m','5m','2m','1m','50cm','25cm']\n",
    "cols = ['max','med','min','p5','p95','range']\n",
    "df_0219 = pd.DataFrame(index=ind, columns=cols, dtype=float)\n",
    "df_0302 = pd.DataFrame(index=ind, columns=cols, dtype=float)\n",
    "df_multi = pd.DataFrame(index=ind, columns=cols, dtype=float)\n",
    "\n",
    "# Add in 10m filenames\n",
    "files_10m_0219 = [f'{metrics_dir}/0219/func_test_{s1_unit}_zonal_0219_10m_{i}.csv' for i in cols]\n",
    "files_10m_0302 = [f'{metrics_dir}/0302/func_test_{s1_unit}_zonal_0304_10m_{i}.csv' for i in cols]\n",
    "subset_0219 = files_10m_0219 + subset_0219\n",
    "subset_0302 = files_10m_0302 + subset_0302\n",
    "\n",
    "\n",
    "def single_to_multi(s):\n",
    "    parts = s.split(re.findall(r'_\\d{4}', s)[0])\n",
    "    full = parts[0] + parts[1]\n",
    "    full = full.replace(re.findall(r'/\\d{4}', full)[0], '')\n",
    "    full = full.replace('single', 'multi')\n",
    "    return full\n",
    "\n",
    "subset_multi = [single_to_multi(f) for f in subset_0219]\n",
    "\n",
    "\n",
    "for f0219, f0302, fmulti in zip(subset_0219, subset_0302, subset_multi):\n",
    "    data_0219 = pd.read_csv(f0219, index_col=0)\n",
    "    data_0302 = pd.read_csv(f0302, index_col=0)\n",
    "    data_multi = pd.read_csv(fmulti, index_col=0)\n",
    "    r2_0219 = data_0219['r2'].mean()\n",
    "    r2_0302 = data_0302['r2'].mean()\n",
    "    r2_multi = data_multi['r2'].mean()\n",
    "    scale = re.findall(r'_\\d{1,2}[a-z]{1,2}_', f0219)[0].split('_')[1]\n",
    "    if scale == '10m':\n",
    "        stat = f0219.split('_')[-1].split('.')[0]\n",
    "    else:\n",
    "        stat = f0219.split('_')[-2]\n",
    "    df_0219.loc[scale, stat] = r2_0219\n",
    "    df_0302.loc[scale, stat] = r2_0302\n",
    "    df_multi.loc[scale, stat] = r2_multi\n",
    "    \n",
    "    \n",
    "cmap = plt.get_cmap('YlGn')#.set_bad('#ff9696')\n",
    "vmin = 0\n",
    "vmax = 0.6\n",
    "\n",
    "dfs = [df_0219, df_0302, df_multi]\n",
    "titles = ['Feb 18 S1 data/Feb 19 UAV data', 'Mar 2 S1 data/Mar 4 UAV data', 'Combined dates']\n",
    "fig, ax = plt.subplots(1, len(dfs), figsize=(9*len(dfs),10))\n",
    "fig.suptitle(f'Final UAV summary statistic: {second_stat}', fontsize=24, y=0.95)\n",
    "j = 0\n",
    "\n",
    "for df in dfs:\n",
    "    im = ax[j].imshow(df, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax[j].set_xticks(np.arange(df.shape[1]+1)-.5, minor=True)\n",
    "    ax[j].set_yticks(np.arange(df.shape[0]+1)-.5, minor=True)\n",
    "    ax[j].grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax[j].tick_params(axis='both', which='minor', bottom=False, left=False)\n",
    "    ax[j].set_xticks(ax[j].get_xticks()[1:-1])\n",
    "    ax[j].set_yticks(ax[j].get_yticks()[1:-1])\n",
    "    ax[j].set_xticklabels(cols, fontsize=16)\n",
    "    ax[j].set_yticklabels(ind, fontsize=16)\n",
    "    cbar_ratio = df.shape[0]/df.shape[1]\n",
    "    cbar = plt.colorbar(im, ax=ax[j], fraction=0.046*cbar_ratio, pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "    if j == len(dfs)-1:\n",
    "        cbar.ax.set_ylabel('Average $R^2$ of 100 RF runs', rotation=-90, \n",
    "                           va='bottom', fontsize=20, labelpad=12)\n",
    "        \n",
    "\n",
    "    for i in range(len(ind)):\n",
    "        for k in range(len(cols)):\n",
    "            text = ax[j].text(k, i, df.iloc[i, k].round(2), fontsize=16,\n",
    "                        ha='center', va='center', color='k')\n",
    "\n",
    "    ax[j].spines['bottom'].set_visible(False)\n",
    "    ax[j].spines['top'].set_visible(False)\n",
    "    ax[j].spines['left'].set_visible(False)\n",
    "    ax[j].spines['right'].set_visible(False)\n",
    "\n",
    "    ax[j].set_xlabel('UAV pixel summary statistic', fontsize=20, labelpad=14)\n",
    "    if j == 0:\n",
    "        ax[j].set_ylabel('UAV subgrid scale', fontsize=20, labelpad=12)\n",
    "\n",
    "\n",
    "    ax[j].set_title(titles[j], fontsize=20)\n",
    "    j += 1\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(f'output/figures/heatmap/full_comparison_{second_stat}_{s1_unit}.png', \n",
    "            facecolor='white', dpi=300)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions of roughness measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loop below takes ~4 mins to run\n",
    "\n",
    "dir_0218 = 'input_data/s1_pixels/0218/'\n",
    "dir_0302 = 'input_data/s1_pixels/0302/'\n",
    "\n",
    "first_loop = True\n",
    "bins = np.logspace(-4, -1, 200)\n",
    "\n",
    "i = 0\n",
    "for d in [dir_0218, dir_0302]:\n",
    "    for f in sorted(glob(f'{d}*.csv')):\n",
    "        data = pd.read_csv(f, index_col=0, na_values=[0])\n",
    "        data.dropna(inplace=True)\n",
    "        data.reset_index(inplace=True)\n",
    "        binned = pd.cut(data['std_dev'], bins=bins, precision=6)\n",
    "        counts = binned.value_counts().sort_index()\n",
    "        \n",
    "        if first_loop:\n",
    "            counts_0218 = pd.Series(np.zeros(len(counts)),\n",
    "                                    index=counts.index, dtype=int)\n",
    "            counts_0302 = pd.Series(np.zeros(len(counts)),\n",
    "                                    index=counts.index, dtype=int)\n",
    "            \n",
    "            first_loop = False\n",
    "        \n",
    "        if i == 0:\n",
    "            counts_0218 += counts\n",
    "        else:\n",
    "            counts_0302 += counts   \n",
    "        \n",
    "    i += 1\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6.5,3))\n",
    "bins_center = (bins[1:] + bins[:-1])/2\n",
    "ax[0].plot(bins_center, counts_0218/counts_0218.sum()/np.diff(bins), lw=2, label='Feb 19')\n",
    "ax[0].plot(bins_center, counts_0302/counts_0302.sum()/np.diff(bins), lw=2, label='Mar 4')\n",
    "# ax[0].set_ylim(-27,600)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].legend(frameon=False, fontsize=11)\n",
    "ax[0].set_ylabel('Observed PDF', fontsize=12, labelpad=10)\n",
    "ax[0].set_xlabel('Surface roughness [m]', fontsize=12)\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "\n",
    "ct_0218 = cumulative_trapezoid(counts_0218/counts_0218.sum()/np.diff(bins), x=bins_center)\n",
    "ct_0302 = cumulative_trapezoid(counts_0302/counts_0302.sum()/np.diff(bins), x=bins_center)\n",
    "ax[1].plot(bins_center[:-1], ct_0218, lw=2)\n",
    "ax[1].plot(bins_center[:-1], ct_0302, lw=2)\n",
    "ax[1].set_xscale('log')\n",
    "# ax[1].legend()\n",
    "ax[1].set_ylabel('Observed CDF', fontsize=12)\n",
    "ax[1].set_xlabel('Surface roughness [m]', fontsize=12)\n",
    "\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('output/figures/distributions/est_densities.pdf', dpi=600)\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
